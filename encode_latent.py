import torch
import torch.multiprocessing as mp
from diffusers import AudioLDM2Pipeline
import moviepy.editor as mp_editor
import librosa
import os
import numpy as np
from tqdm import tqdm
import traceback
from audioldm2.utils import default_audioldm_config
from audioldm2.utilities.audio.stft import TacotronSTFT

# --- ä¼˜åŒ–ç‚¹: å°†é…ç½®å’ŒSTFTå¯¹è±¡åˆ›å»ºç§»è‡³æ¯ä¸ªè¿›ç¨‹çš„é¡¶å±‚ ---
# å°†é…ç½®è®¾ä¸ºå…¨å±€ï¼Œæ–¹ä¾¿æ‰€æœ‰è¿›ç¨‹è®¿é—®
config = default_audioldm_config()

def setup_audioldm2_vae(gpu_id, repo_id="cvssp/audioldm2", torch_dtype=torch.float16):
    """
    åŠ è½½å¹¶è®¾ç½® AudioLDM 2 VAE æ¨¡å‹åˆ°æŒ‡å®šçš„GPUä¸Šã€‚
    """
    device = f"cuda:{gpu_id}"
    print(f"[GPU-{gpu_id}]: æ­£åœ¨åŠ è½½ AudioLDM 2 æ¨¡å‹åˆ° {device}...")
    pipe = AudioLDM2Pipeline.from_pretrained(repo_id, torch_dtype=torch_dtype, resume_download=True)
    pipe = pipe.to(device)
    print(f"[GPU-{gpu_id}]: æ¨¡å‹å·²æˆåŠŸåŠ è½½ã€‚")
    # feature_extractor åœ¨æ–°ç‰ˆæœ¬ä¸­é€šå¸¸ä¸æ˜¯å¿…éœ€çš„
    return pipe.vae, device

# ##################################################################
# ## ä»¥ä¸‹æ˜¯ç»è¿‡ä¿®æ­£å’Œä¼˜åŒ–çš„éŸ³é¢‘å¤„ç†è¾…åŠ©å‡½æ•° ##
# ##################################################################

def _pad_spec(fbank: torch.Tensor, target_length: int):
    """
    ã€ä¿®æ­£ç‰ˆã€‘è¾…åŠ©å‡½æ•°ï¼šå°†é¢‘è°±å›¾è¡¥é½æˆ–è£å‰ªåˆ°ç›®æ ‡é•¿åº¦ã€‚å…¨ç¨‹ä½¿ç”¨PyTorchæ“ä½œã€‚
    """
    n_frames = fbank.shape[0]
    if n_frames > target_length:
        # é•¿åº¦è¶…å‡ºï¼Œåˆ™è£å‰ª
        fbank = fbank[:target_length, :]
    elif n_frames < target_length:
        # é•¿åº¦ä¸è¶³ï¼Œåˆ™ç”¨0è¡¥é½
        pad_width = target_length - n_frames
        # ä½¿ç”¨ torch.nn.functional.padï¼Œå‚æ•°æ ¼å¼ä¸º (å·¦, å³, ä¸Š, ä¸‹)
        fbank = torch.nn.functional.pad(fbank, (0, 0, 0, pad_width), mode='constant', value=0)
    return fbank

def get_mel_from_wav(waveform: torch.Tensor, _stft: TacotronSTFT):
    """
    ã€ä¿®æ­£ç‰ˆã€‘è¾…åŠ©å‡½æ•°ï¼šä»æ³¢å½¢Tensorè®¡ç®—æ¢…å°”é¢‘è°±ã€‚å…¨ç¨‹ä¿æŒåœ¨PyTorchä¸­ï¼Œä¸è½¬å›NumPyã€‚
    """
    # ç¡®ä¿è¾“å…¥æ˜¯æ­£ç¡®çš„å½¢çŠ¶ [batch_size, n_samples]
    if waveform.ndim == 1:
        waveform = waveform.unsqueeze(0)

    # ç›´æ¥è°ƒç”¨STFTå¯¹è±¡çš„mel_spectrogramæ–¹æ³•ï¼Œå…¶è¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯Tensor
    melspec, magnitudes, _, _ = _stft.mel_spectrogram(waveform)
    
    # ç§»é™¤æ‰¹æ¬¡ç»´åº¦ï¼Œè¿”å›çº¯Tensor
    return melspec.squeeze(0), magnitudes.squeeze(0)

def waveform_to_fbank(
    waveform: torch.Tensor,
    target_length: int,
    fn_STFT: TacotronSTFT
):
    """
    ã€ä¿®æ­£ç‰ˆã€‘ä¼˜åŒ–å‡½æ•°ï¼Œå°†æ³¢å½¢Tensoré«˜æ•ˆè½¬æ¢ä¸ºfbankã€‚
    """
    assert torch.is_tensor(waveform), "è¾“å…¥ 'waveform' å¿…é¡»æ˜¯ PyTorch tensor."
    
    # 1. è®¡ç®—æ¢…å°”é¢‘è°±ï¼Œå…¨ç¨‹ä½¿ç”¨Tensor
    fbank_T, _ = get_mel_from_wav(waveform, fn_STFT)

    # 2. è½¬ç½®ç»´åº¦ [n_mels, time] -> [time, n_mels]
    fbank = fbank_T.T

    # 3. è¡¥é½æˆ–è£å‰ª
    fbank = _pad_spec(fbank, target_length)

    return fbank, None # ä¿æŒä¸åŸå‡½æ•°ç›¸åŒçš„è¿”å›æ ¼å¼

# ##################################################################
# ## æ ¸å¿ƒä¿®æ”¹ï¼šé‡å†™ encode_audio_from_video å‡½æ•° ##
# ##################################################################

def encode_audio_from_video(
    video_path: str,
    vae,
    device: str,
    fn_STFT: TacotronSTFT # æ¥æ”¶é¢„å…ˆåˆ›å»ºå¥½çš„STFTå¤„ç†å™¨
):
    """
    ã€ä¼˜åŒ–ç‰ˆã€‘ä»è§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³é¢‘ï¼Œå¹¶å°†å…¶ç¼–ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚
    æ­¤ç‰ˆæœ¬åœ¨å†…å­˜ä¸­å®Œæˆæ‰€æœ‰æ“ä½œï¼Œé¿å…äº†ç£ç›˜I/Oï¼Œå¹¶å¢åŠ äº†æ•°æ®æ ¡éªŒã€‚
    """
    try:
        with mp_editor.VideoFileClip(video_path) as video_clip:
            if video_clip.audio is None:
                return None, "NO_AUDIO"
            
            # 1. ã€ä¼˜åŒ–ã€‘ç›´æ¥å°†éŸ³é¢‘è§£ç åˆ°å†…å­˜ä¸­çš„NumPyæ•°ç»„
            audio_array = video_clip.audio.to_soundarray(fps=config["preprocessing"]["audio"]["sampling_rate"])
            
            # å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œåˆ™æ··åˆä¸ºå•å£°é“
            if audio_array.ndim > 1 and audio_array.shape[1] > 1:
                audio_array = np.mean(audio_array, axis=1)

        # 2. ã€é²æ£’æ€§ã€‘åœ¨å¤„ç†å‰æ£€æŸ¥æ˜¯å¦å­˜åœ¨æŸåçš„éŸ³é¢‘æ•°æ® (NaN æˆ– Inf)
        if np.isnan(audio_array).any() or np.isinf(audio_array).any():
            return None, f"INVALID_AUDIO (NaN/Inf) in {os.path.basename(video_path)}"

        # 3. ã€ä¼˜åŒ–ã€‘å°†NumPyæ•°ç»„è½¬æ¢ä¸ºPyTorch Tensorï¼ˆè¿™æ˜¯å”¯ä¸€å¿…è¦çš„è½¬æ¢ï¼‰
        waveform = torch.from_numpy(audio_array.copy()).float()
        
        # 4. ã€ä¼˜åŒ–ã€‘è°ƒç”¨é«˜æ•ˆçš„å†…å­˜è®¡ç®—å‡½æ•°
        mel, _ = waveform_to_fbank(
            waveform=waveform,
            target_length=int(3 * 102.4),  # å‡è®¾æ—¶é•¿ä¸º3ç§’
            fn_STFT=fn_STFT
        )
        
        # 5. å‡†å¤‡è¾“å…¥ç»™VAEçš„Tensorï¼ˆå¢åŠ æ‰¹æ¬¡å’Œé€šé“ç»´åº¦ï¼Œå¹¶ç§»åŠ¨åˆ°GPUï¼‰
        mel = mel.unsqueeze(0).unsqueeze(0).to(device, dtype=torch.float16)

        # 6. ä½¿ç”¨VAEè¿›è¡Œç¼–ç 
        with torch.no_grad():
            latent_representation = vae.encode(mel).latent_dist.mode()
        
        return latent_representation.cpu().numpy(), "SUCCESS"

    except Exception as e:
        error_message = f"å¤„ç†æ–‡ä»¶ '{os.path.basename(video_path)}' æ—¶å‡ºé”™: {e}\n{traceback.format_exc()}"
        return None, error_message
    # ä¸å†éœ€è¦ finally å—ï¼Œå› ä¸ºæ²¡æœ‰ä¸´æ—¶æ–‡ä»¶äº†

def process_files_on_gpu(gpu_id, file_chunk, input_dir, output_dir):
    """
    å·¥ä½œå‡½æ•°ï¼Œç”±å•ä¸ªè¿›ç¨‹æ‰§è¡Œã€‚
    """
    try:
        vae, device = setup_audioldm2_vae(gpu_id)
    except Exception as e:
        print(f"[GPU-{gpu_id}]: æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return len(file_chunk), 0

    # --- ä¼˜åŒ–ç‚¹: åœ¨æ¯ä¸ªè¿›ç¨‹ä¸­åªåˆ›å»ºä¸€æ¬¡STFTå¤„ç†å™¨ ---
    fn_STFT = TacotronSTFT(
        config["preprocessing"]["stft"]["filter_length"],
        config["preprocessing"]["stft"]["hop_length"],
        config["preprocessing"]["stft"]["win_length"],
        config["preprocessing"]["mel"]["n_mel_channels"],
        config["preprocessing"]["audio"]["sampling_rate"],
        config["preprocessing"]["mel"]["mel_fmin"],
        config["preprocessing"]["mel"]["mel_fmax"],
    )

    error_count = 0
    success_count = 0
    progress_bar = tqdm(file_chunk, desc=f"GPU-{gpu_id} å¤„ç†ä¸­", position=gpu_id)
    
    for filename in progress_bar:
        video_path = os.path.join(input_dir, filename)
        base_name = os.path.splitext(filename)[0]
        output_path = os.path.join(output_dir, f"{base_name}.npy")

        # å°†é¢„å…ˆåˆ›å»ºå¥½çš„ fn_STFT å¯¹è±¡ä¼ é€’ä¸‹å»
        latent_np, status = encode_audio_from_video(video_path, vae, device, fn_STFT)

        if status == "SUCCESS" and latent_np is not None:
            np.save(output_path, latent_np)
            success_count += 1
        elif status not in ["SUCCESS", "NO_AUDIO"]:
            tqdm.write(f"[GPU-{gpu_id} å·²è·³è¿‡]: æ–‡ä»¶: {filename}, åŸå› : {status}")
            error_count += 1
            
    return error_count, success_count

# `batch_process_videos_multi_gpu` å’Œ `if __name__ == '__main__':` éƒ¨åˆ†ä¿æŒä¸å˜
# ... (æ‚¨çš„è¿™éƒ¨åˆ†ä»£ç æ˜¯æ­£ç¡®çš„ï¼Œæ— éœ€ä¿®æ”¹)
def batch_process_videos_multi_gpu(input_dir, output_dir):
    """
    ä¸»å‡½æ•°ï¼šè´Ÿè´£ä»»åŠ¡åˆ†å‘å’Œå¯åŠ¨å¤šè¿›ç¨‹ã€‚
    """
    # --- 1. æ£€æŸ¥GPUæ•°é‡ ---
    if not torch.cuda.is_available():
        print("é”™è¯¯ï¼šæœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ã€‚è¯·åœ¨å•å¡CPU/GPUæ¨¡å¼ä¸‹è¿è¡Œã€‚")
        return

    num_gpus = torch.cuda.device_count()
    print(f"æ£€æµ‹åˆ° {num_gpus} å—å¯ç”¨çš„GPUã€‚")

    # --- 2. æ£€æŸ¥å¹¶åˆ›å»ºè¾“å‡ºç›®å½• ---
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"å·²åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")

    # --- 3. æŸ¥æ‰¾æ‰€æœ‰è¦å¤„ç†çš„ MP4 æ–‡ä»¶ ---
    all_files = sorted([f for f in os.listdir(input_dir) if f.lower().endswith(".mp4")])
    if not all_files:
        print(f"åœ¨ç›®å½• '{input_dir}' ä¸­æ²¡æœ‰æ‰¾åˆ° .mp4 æ–‡ä»¶ã€‚")
        return
        
    print(f"åœ¨è¾“å…¥ç›®å½•ä¸­æ‰¾åˆ° {len(all_files)} ä¸ª .mp4 æ–‡ä»¶ã€‚å‡†å¤‡åˆ†å‘ä»»åŠ¡...")

    # --- 4. å°†æ–‡ä»¶åˆ—è¡¨å¹³å‡åˆ†é…ç»™æ¯ä¸ªGPU ---
    # ä½¿ç”¨ np.array_split å¯ä»¥ä¼˜é›…åœ°å¤„ç†æ— æ³•æ•´é™¤çš„æƒ…å†µ
    file_chunks = np.array_split(all_files, num_gpus)
    
    # å‡†å¤‡ä¼ é€’ç»™æ¯ä¸ªå·¥ä½œè¿›ç¨‹çš„å‚æ•°
    tasks = []
    for gpu_id, chunk in enumerate(file_chunks):
        if len(chunk) > 0: # åªæœ‰å½“åˆ†é…åˆ°æ–‡ä»¶æ—¶æ‰åˆ›å»ºä»»åŠ¡
            tasks.append((gpu_id, list(chunk), input_dir, output_dir))
            print(f"  -> GPU-{gpu_id} å°†å¤„ç† {len(chunk)} ä¸ªæ–‡ä»¶ã€‚")

    # --- 5. åˆ›å»ºå¹¶å¯åŠ¨è¿›ç¨‹æ±  ---
    # ä½¿ç”¨ 'spawn' å¯åŠ¨æ–¹æ³•ï¼Œè¿™å¯¹CUDAæ˜¯å¿…é¡»çš„ï¼Œå¯ä»¥é¿å…å¾ˆå¤šæ½œåœ¨çš„æ­»é”é—®é¢˜
    ctx = mp.get_context('spawn')
    with ctx.Pool(processes=len(tasks)) as pool:
        # ä½¿ç”¨ starmap æ¥ä¼ é€’å¤šä¸ªå‚æ•°ç»™å·¥ä½œå‡½æ•°
        results = pool.starmap(process_files_on_gpu, tasks)

    # --- 6. æ±‡æ€»ç»“æœ ---
    total_errors = sum([res[0] for res in results])
    total_success = sum([res[1] for res in results])

    print("\n--- å¤„ç†å®Œæˆï¼Œç”ŸæˆæŠ¥å‘Š ---")
    print(f"æ€»è®¡æˆåŠŸå¤„ç†: {total_success} ä¸ªæ–‡ä»¶")
    print(f"æ€»è®¡å¤„ç†å¤±è´¥: {total_errors} ä¸ªæ–‡ä»¶")
    print("\nğŸ‰ æ‰€æœ‰è§†é¢‘å¤„ç†å®Œæˆï¼")


if __name__ == '__main__':
    # ä¸ºäº†åœ¨ä½¿ç”¨CUDAæ—¶è·å¾—æœ€ä½³çš„å¤šè¿›ç¨‹ç¨³å®šæ€§ï¼Œå»ºè®®è®¾ç½®å¯åŠ¨æ–¹æ³•
    # 'spawn' ä¼šåˆ›å»ºä¸€ä¸ªå…¨æ–°çš„Pythonè§£é‡Šå™¨è¿›ç¨‹ï¼Œè€Œä¸æ˜¯'fork'ä¸€ä¸ªç°æœ‰è¿›ç¨‹
    # è¿™å¯ä»¥é¿å…CUDAåˆå§‹åŒ–çŠ¶æ€åœ¨å­è¿›ç¨‹ä¸­å‡ºç°é—®é¢˜ã€‚
    # å¿…é¡»åœ¨ if __name__ == '__main__': å—çš„å¼€å¤´è®¾ç½®ã€‚
    try:
        mp.set_start_method('spawn', force=True)
    except RuntimeError:
        pass
        
    video_directory_list=["vggsound_00_3s","vggsound_01_3s","vggsound_02_3s","vggsound_03_3s","vggsound_04_3s"]
    input_video_directory_base="/blob/vggsound_cropped"
    output_latent_directory_base = "/blob/vggsound_cropped_audio_latent"
    # --------------------------
    for video_dir in video_directory_list:
        input_video_directory=os.path.join(input_video_directory_base,video_dir)
        output_latent_directory=os.path.join(output_latent_directory_base,video_dir)

        try:
            batch_process_videos_multi_gpu(input_video_directory, output_latent_directory)
        except Exception as e:
            print(f"\nç¨‹åºè¿è¡ŒæœŸé—´å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            print(traceback.format_exc())