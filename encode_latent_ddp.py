import torch
import torch.distributed as dist
import torch.multiprocessing as mp
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.distributed import DistributedSampler
from diffusers import AudioLDM2Pipeline
import torchaudio
import librosa
import os
import numpy as np
from tqdm import tqdm
import traceback
from audioldm2.utils import default_audioldm_config
from audioldm2.utilities.audio.stft import TacotronSTFT

# ========== éŸ³é¢‘å¤„ç†å‡½æ•°ä¿æŒä¸å˜ ==========
def get_mel_from_wav(audio, _stft):
    audio = torch.clip(torch.FloatTensor(audio).unsqueeze(0), -1, 1)
    audio = torch.autograd.Variable(audio, requires_grad=False)
    melspec, magnitudes, phases, energy = _stft.mel_spectrogram(audio)
    melspec = torch.squeeze(melspec, 0).numpy().astype(np.float32)
    magnitudes = torch.squeeze(magnitudes, 0).numpy().astype(np.float32)
    energy = torch.squeeze(energy, 0).numpy().astype(np.float32)
    return melspec, magnitudes, energy

def pad_wav(waveform, segment_length):
    waveform_length = waveform.shape[-1]
    assert waveform_length > 100, "Waveform is too short, %s" % waveform_length
    if segment_length is None or waveform_length == segment_length:
        return waveform
    elif waveform_length > segment_length:
        return waveform[:segment_length]
    elif waveform_length < segment_length:
        temp_wav = np.zeros((1, segment_length))
        temp_wav[:, :waveform_length] = waveform
    return temp_wav

def _pad_spec(fbank, target_length=1024):
    n_frames = fbank.shape[0]
    p = target_length - n_frames
    if p > 0:
        m = torch.nn.ZeroPad2d((0, 0, 0, p))
        fbank = m(fbank)
    elif p < 0:
        fbank = fbank[0:target_length, :]
    if fbank.size(-1) % 2 != 0:
        fbank = fbank[..., :-1]
    return fbank

def normalize_wav(waveform):
    waveform = waveform - np.mean(waveform)
    waveform = waveform / (np.max(np.abs(waveform)) + 1e-8)
    return waveform * 0.5

def read_wav_file(filename, segment_length):
    waveform, sr = torchaudio.load(filename,format="mp4",backend="ffmpeg")
    waveform = torchaudio.functional.resample(waveform, orig_freq=sr, new_freq=16000)
    waveform = waveform.numpy()[0, ...]
    waveform = normalize_wav(waveform)
    waveform = waveform[None, ...]
    waveform = pad_wav(waveform, segment_length)
    return waveform

def wav_to_fbank(filename, target_length=1024, fn_STFT=None):
    assert fn_STFT is not None
    waveform = read_wav_file(filename, target_length * 160)
    waveform = waveform[0, ...]
    waveform = torch.FloatTensor(waveform)
    fbank, log_magnitudes_stft, energy = get_mel_from_wav(waveform, fn_STFT)
    fbank = torch.FloatTensor(fbank.T)
    log_magnitudes_stft = torch.FloatTensor(log_magnitudes_stft.T)
    fbank, log_magnitudes_stft = _pad_spec(fbank, target_length), _pad_spec(
        log_magnitudes_stft, target_length
    )
    return fbank, log_magnitudes_stft, waveform

def encode_audio_from_video(video_path, vae, fn_STFT, device):
    try:
        config=default_audioldm_config()
        duration=3
        mel, _, _ = wav_to_fbank(
            video_path, target_length=int(duration * 102.4), fn_STFT=fn_STFT
        )
        mel=mel.unsqueeze(0).unsqueeze(0).to(device).to(torch.float16)
        with torch.no_grad():
            latent_representation  = vae.encode(mel).latent_dist.mode()
        return latent_representation.cpu().numpy(), "SUCCESS"
    except Exception as e:
        error_message = f"å¤„ç†æ–‡ä»¶ '{os.path.basename(video_path)}' æ—¶å‘ç”Ÿé”™è¯¯: {e}\n{traceback.format_exc()}"
        return None, error_message

# ========== æ”¹è¿›çš„Datasetç±»ï¼Œæ”¯æŒå¤šä¸ªç›®å½• ==========
class MultiDirectoryVideoDataset(Dataset):
    """æ”¯æŒå¤šä¸ªç›®å½•çš„æ•°æ®é›†ç±»"""
    def __init__(self, video_directory_list, input_base_dir, output_base_dir):
        self.files = []
        
        for video_dir in video_directory_list:
            input_dir = os.path.join(input_base_dir, video_dir)
            output_dir = os.path.join(output_base_dir, video_dir)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            if not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)
            
            # æ”¶é›†è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
            for filename in sorted(os.listdir(input_dir)):
                if filename.lower().endswith(".mp4"):
                    video_path = os.path.join(input_dir, filename)
                    base_name = os.path.splitext(filename)[0]
                    output_path = os.path.join(output_dir, f"{base_name}.npy")
                    self.files.append((video_path, output_path, video_dir))
        
        print(f"æ€»è®¡æ‰¾åˆ° {len(self.files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        
    def __len__(self):
        return len(self.files)
    
    def __getitem__(self, idx):
        return self.files[idx]

def setup_ddp(rank, world_size):
    """åˆå§‹åŒ–DDPçŽ¯å¢ƒ"""
    os.environ['MASTER_ADDR'] = '127.0.0.1'
    os.environ['MASTER_PORT'] = '12355'
    dist.init_process_group("nccl", rank=rank, world_size=world_size)
    torch.cuda.set_device(rank)

def cleanup():
    """æ¸…ç†DDP"""
    dist.destroy_process_group()

def setup_audioldm2_vae_ddp(rank, repo_id="cvssp/audioldm2", torch_dtype=torch.float16):
    """ä¸ºDDPåŠ è½½å¹¶è®¾ç½®AudioLDM 2 VAEæ¨¡åž‹"""
    device = torch.device(f"cuda:{rank}")
    
    if rank == 0:
        print(f"[Rank {rank}]: æ­£åœ¨åŠ è½½ AudioLDM 2 æ¨¡åž‹ï¼ˆä»…åŠ è½½ä¸€æ¬¡ï¼‰...")
    
    pipe = AudioLDM2Pipeline.from_pretrained(repo_id, torch_dtype=torch_dtype, resume_download=True)
    pipe = pipe.to(device)
    
    if rank == 0:
        print(f"[Rank {rank}]: æ¨¡åž‹å·²æˆåŠŸåŠ è½½ã€‚")
    
    return pipe.vae, pipe.feature_extractor, device

def process_all_directories_ddp(rank, world_size, video_directory_list, input_base_dir, output_base_dir):
    """DDPå·¥ä½œå‡½æ•°ï¼Œä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰ç›®å½•"""
    # è®¾ç½®DDP
    setup_ddp(rank, world_size)
    
    try:
        # åŠ è½½æ¨¡åž‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
        vae, _, device = setup_audioldm2_vae_ddp(rank)
        
        # åˆ›å»ºåŒ…å«æ‰€æœ‰ç›®å½•çš„æ•°æ®é›†
        dataset = MultiDirectoryVideoDataset(video_directory_list, input_base_dir, output_base_dir)
        
        # åˆ›å»ºåˆ†å¸ƒå¼é‡‡æ ·å™¨
        sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank, shuffle=False)
        
        # æ‰¹æ¬¡å¤§å°è®¾ä¸º1ï¼Œå› ä¸ºè§†é¢‘æ–‡ä»¶é€šå¸¸è¾ƒå¤§
        dataloader = DataLoader(
            dataset, 
            batch_size=1, 
            sampler=sampler, 
            num_workers=2,  # é€‚åº¦çš„workeræ•°é‡
            pin_memory=True,
            prefetch_factor=2,
            persistent_workers=True
        )
        
        # è®¾ç½®STFT
        config = default_audioldm_config()
        fn_STFT = TacotronSTFT(
            config["preprocessing"]["stft"]["filter_length"],
            config["preprocessing"]["stft"]["hop_length"],
            config["preprocessing"]["stft"]["win_length"],
            config["preprocessing"]["mel"]["n_mel_channels"],
            config["preprocessing"]["audio"]["sampling_rate"],
            config["preprocessing"]["mel"]["mel_fmin"],
            config["preprocessing"]["mel"]["mel_fmax"],
        )
        
        error_count = 0
        success_count = 0
        current_dir = None
        dir_stats = {}
        
        # åªåœ¨rank 0æ˜¾ç¤ºè¿›åº¦æ¡
        iterator = tqdm(dataloader, desc=f"Rank {rank} å¤„ç†ä¸­", total=len(dataloader)) if rank == 0 else dataloader
        
        for batch in iterator:
            video_path, output_path, video_dir = batch
            video_path = video_path[0]  # è§£åŒ…batch
            output_path = output_path[0]
            video_dir = video_dir[0]
            
            # æ£€æµ‹ç›®å½•å˜åŒ–ï¼Œç”¨äºŽæ˜¾ç¤ºè¿›åº¦
            if current_dir != video_dir:
                if current_dir is not None and rank == 0:
                    print(f"\n[Rank {rank}] å®Œæˆç›®å½•: {current_dir}")
                current_dir = video_dir
                if rank == 0:
                    print(f"\n[Rank {rank}] å¼€å§‹å¤„ç†ç›®å½•: {video_dir}")
                
                # åˆå§‹åŒ–ç›®å½•ç»Ÿè®¡
                if video_dir not in dir_stats:
                    dir_stats[video_dir] = {'success': 0, 'error': 0}
            
            # å¦‚æžœæ–‡ä»¶å·²å­˜åœ¨åˆ™è·³è¿‡
            if os.path.exists(output_path):
                success_count += 1
                dir_stats[video_dir]['success'] += 1
                continue
            
            # å¤„ç†æ–‡ä»¶
            latent_np, status = encode_audio_from_video(video_path, vae, fn_STFT, device)
            
            if status == "SUCCESS" and latent_np is not None:
                try:
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    os.makedirs(os.path.dirname(output_path), exist_ok=True)
                    np.save(output_path, latent_np)
                    success_count += 1
                    dir_stats[video_dir]['success'] += 1
                except Exception as e:
                    if rank == 0:
                        print(f"[Rank {rank}] ä¿å­˜å¤±è´¥: {e}")
                    error_count += 1
                    dir_stats[video_dir]['error'] += 1
            else:
                if rank == 0:
                    print(f"[Rank {rank} é”™è¯¯]: {status}")
                error_count += 1
                dir_stats[video_dir]['error'] += 1
        
        # æ”¶é›†æ‰€æœ‰rankçš„ç»Ÿè®¡ä¿¡æ¯
        error_tensor = torch.tensor([error_count], device=device)
        success_tensor = torch.tensor([success_count], device=device)
        
        dist.all_reduce(error_tensor, op=dist.ReduceOp.SUM)
        dist.all_reduce(success_tensor, op=dist.ReduceOp.SUM)
        
        if rank == 0:
            print("\n" + "="*50)
            print("å¤„ç†å®Œæˆï¼Œè¯¦ç»†ç»Ÿè®¡ï¼š")
            print("="*50)
            for video_dir in dir_stats:
                print(f"{video_dir}: æˆåŠŸ {dir_stats[video_dir]['success']}, å¤±è´¥ {dir_stats[video_dir]['error']}")
            print("="*50)
            print(f"æ€»è®¡æˆåŠŸå¤„ç†: {success_tensor.item()} ä¸ªæ–‡ä»¶")
            print(f"æ€»è®¡å¤„ç†å¤±è´¥: {error_tensor.item()} ä¸ªæ–‡ä»¶")
            
    except Exception as e:
        print(f"[Rank {rank}]: å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
    finally:
        cleanup()

def batch_process_all_videos_ddp(video_directory_list, input_base_dir, output_base_dir):
    """ä¸»å‡½æ•°ï¼šä¸€æ¬¡æ€§ä½¿ç”¨DDPå¤„ç†æ‰€æœ‰ç›®å½•çš„è§†é¢‘"""
    # æ£€æŸ¥GPUæ•°é‡
    if not torch.cuda.is_available():
        print("é”™è¯¯ï¼šæœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ã€‚")
        return
    
    world_size = torch.cuda.device_count()
    print(f"æ£€æµ‹åˆ° {world_size} å—å¯ç”¨çš„GPUï¼Œå°†ä½¿ç”¨DDPè¿›è¡Œå¤„ç†ã€‚")
    print(f"å¾…å¤„ç†çš„ç›®å½•æ•°é‡: {len(video_directory_list)}")
    print(f"ç›®å½•åˆ—è¡¨: {video_directory_list}")
    
    # ç¡®ä¿åŸºç¡€è¾“å‡ºç›®å½•å­˜åœ¨
    if not os.path.exists(output_base_dir):
        os.makedirs(output_base_dir)
        print(f"å·²åˆ›å»ºè¾“å‡ºåŸºç¡€ç›®å½•: {output_base_dir}")
    
    # ä½¿ç”¨spawnå¯åŠ¨DDPè¿›ç¨‹ï¼ˆåªå¯åŠ¨ä¸€æ¬¡ï¼‰
    mp.spawn(
        process_all_directories_ddp,
        args=(world_size, video_directory_list, input_base_dir, output_base_dir),
        nprocs=world_size,
        join=True
    )
    
    print("\nðŸŽ‰ æ‰€æœ‰ç›®å½•çš„è§†é¢‘å¤„ç†å®Œæˆï¼")

if __name__ == '__main__':
    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•
    try:
        mp.set_start_method('spawn', force=True)
    except RuntimeError:
        pass
    
    # æ‰€æœ‰å¾…å¤„ç†çš„ç›®å½•åˆ—è¡¨
    video_directory_list = ["vggsound_00_3s","vggsound_01_3s","vggsound_02_3s","vggsound_03_3s","vggsound_04_3s", 
    "vggsound_06_3s", "vggsound_07_3s", "vggsound_08_3s", "vggsound_09_3s",
        "vggsound_10_3s", "vggsound_11_3s", "vggsound_12_3s", "vggsound_13_3s", "vggsound_14_3s",
        "vggsound_15_3s", "vggsound_16_3s", "vggsound_17_3s", "vggsound_18_3s", "vggsound_19_3s",
    ]
    
    input_video_directory_base = "/blob/vggsound_cropped"
    output_latent_directory_base = "/blob/vggsound_cropped_audio_latent_fixed"
    
    # ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰ç›®å½•ï¼ˆæ¨¡åž‹åªåŠ è½½ä¸€æ¬¡ï¼‰
    try:
        batch_process_all_videos_ddp(
            video_directory_list, 
            input_video_directory_base, 
            output_latent_directory_base
        )
    except Exception as e:
        print(f"\nç¨‹åºè¿è¡ŒæœŸé—´å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        print(traceback.format_exc())
