import torch
import torch.multiprocessing as mp
from diffusers import AudioLDM2Pipeline
import torchaudio
import librosa
import os
import numpy as np
from tqdm import tqdm
import traceback
from audioldm2.utils import default_audioldm_config
from audioldm2.utilities.audio.stft import TacotronSTFT
# from audioldm2.utilities.audio.tools import wav_to_fbank
def get_mel_from_wav(audio, _stft):
    audio = torch.clip(torch.FloatTensor(audio).unsqueeze(0), -1, 1)
    audio = torch.autograd.Variable(audio, requires_grad=False)
    melspec, magnitudes, phases, energy = _stft.mel_spectrogram(audio)
    melspec = torch.squeeze(melspec, 0).numpy().astype(np.float32)
    magnitudes = torch.squeeze(magnitudes, 0).numpy().astype(np.float32)
    energy = torch.squeeze(energy, 0).numpy().astype(np.float32)
    return melspec, magnitudes, energy
def setup_audioldm2_vae(gpu_id, repo_id="cvssp/audioldm2", torch_dtype=torch.float16):
    """
    åŠ è½½å¹¶è®¾ç½® AudioLDM 2 VAE æ¨¡å‹åˆ°æŒ‡å®šçš„GPUä¸Šã€‚
    è¿™ä¸ªå‡½æ•°å°†åœ¨æ¯ä¸ªç‹¬ç«‹çš„å·¥ä½œè¿›ç¨‹ä¸­è¢«è°ƒç”¨ã€‚
    """
    device = f"cuda:{gpu_id}"
    print(f"[GPU-{gpu_id}]: æ­£åœ¨åŠ è½½ AudioLDM 2 æ¨¡å‹åˆ° {device}...")
    pipe = AudioLDM2Pipeline.from_pretrained(repo_id, torch_dtype=torch_dtype, resume_download=True)
    pipe = pipe.to(device)
    print(f"[GPU-{gpu_id}]: æ¨¡å‹å·²æˆåŠŸåŠ è½½ã€‚")
    return pipe.vae, pipe.feature_extractor, device
def pad_wav(waveform, segment_length):
    waveform_length = waveform.shape[-1]
    assert waveform_length > 100, "Waveform is too short, %s" % waveform_length
    if segment_length is None or waveform_length == segment_length:
        return waveform
    elif waveform_length > segment_length:
        return waveform[:segment_length]
    elif waveform_length < segment_length:
        temp_wav = np.zeros((1, segment_length))
        temp_wav[:, :waveform_length] = waveform
    return temp_wav

def _pad_spec(fbank, target_length=1024):
    n_frames = fbank.shape[0]
    p = target_length - n_frames
    # cut and pad
    if p > 0:
        m = torch.nn.ZeroPad2d((0, 0, 0, p))
        fbank = m(fbank)
    elif p < 0:
        fbank = fbank[0:target_length, :]

    if fbank.size(-1) % 2 != 0:
        fbank = fbank[..., :-1]

    return fbank

def normalize_wav(waveform):
    waveform = waveform - np.mean(waveform)
    waveform = waveform / (np.max(np.abs(waveform)) + 1e-8)
    return waveform * 0.5
def read_wav_file(filename, segment_length):
    # waveform, sr = librosa.load(filename, sr=None, mono=True) # 4 times slower
    waveform, sr = torchaudio.load(filename,format="mp4",backend="ffmpeg")  # Faster!!!
    waveform = torchaudio.functional.resample(waveform, orig_freq=sr, new_freq=16000)
    waveform = waveform.numpy()[0, ...]
    waveform = normalize_wav(waveform)
    waveform = waveform[None, ...]
    waveform = pad_wav(waveform, segment_length)

    # waveform = waveform / np.max(np.abs(waveform))
    # waveform = 0.5 * waveform

    return waveform
def wav_to_fbank(filename, target_length=1024, fn_STFT=None):
    assert fn_STFT is not None

    # mixup
    waveform = read_wav_file(filename, target_length * 160)  # hop size is 160

    waveform = waveform[0, ...]
    waveform = torch.FloatTensor(waveform)

    fbank, log_magnitudes_stft, energy = get_mel_from_wav(waveform, fn_STFT)

    fbank = torch.FloatTensor(fbank.T)
    log_magnitudes_stft = torch.FloatTensor(log_magnitudes_stft.T)

    fbank, log_magnitudes_stft = _pad_spec(fbank, target_length), _pad_spec(
        log_magnitudes_stft, target_length
    )

    return fbank, log_magnitudes_stft, waveform


def encode_audio_from_video(video_path, vae, feature_extractor, device):
    """
    ä»å•ä¸ªè§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³é¢‘ï¼Œå¹¶ä½¿ç”¨ç»™å®šçš„ VAE å°†å…¶ç¼–ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚
    """
    # åˆ›å»ºä¸€ä¸ªåŸºäºè¿›ç¨‹å’Œæ–‡ä»¶åçš„å”¯ä¸€ä¸´æ—¶æ–‡ä»¶ï¼Œé¿å…å†²çª
    # temp_audio_path = f"temp_audio_{os.getpid()}_{os.path.basename(video_path)}.wav"
    try:
 
        config=default_audioldm_config()
        # 2. åŠ è½½å¹¶é¢„å¤„ç†æå–çš„éŸ³é¢‘
        fn_STFT = TacotronSTFT(
            config["preprocessing"]["stft"]["filter_length"],
            config["preprocessing"]["stft"]["hop_length"],
            config["preprocessing"]["stft"]["win_length"],
            config["preprocessing"]["mel"]["n_mel_channels"],
            config["preprocessing"]["audio"]["sampling_rate"],
            config["preprocessing"]["mel"]["mel_fmin"],
            config["preprocessing"]["mel"]["mel_fmax"],
        )
        duration=3
        # waveform = read_wav_file(original_audio_file_path, None)
        mel, _, _ = wav_to_fbank(
            video_path, target_length=int(duration * 102.4), fn_STFT=fn_STFT
        )
        mel=mel.unsqueeze(0).unsqueeze(0).to(device).to(torch.float16)

        # 3. ä½¿ç”¨ VAE è¿›è¡Œç¼–ç 
        with torch.no_grad():
            latent_representation  = vae.encode(mel).latent_dist.mode()
        
        return latent_representation.cpu().numpy(), "SUCCESS"

    except Exception as e:
        error_message = f"å¤„ç†æ–‡ä»¶ '{os.path.basename(video_path)}' æ—¶å‘ç”Ÿé”™è¯¯: {e}\n{traceback.format_exc()}"
        return None, error_message
    # finally:
    #     # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    #     if os.path.exists(temp_audio_path):
    #         try:
    #             os.remove(temp_audio_path)
    #         except OSError:
    #             pass

def process_files_on_gpu(gpu_id, file_chunk, input_dir, output_dir):
    """
    è¿™æ˜¯ä¸€ä¸ªå·¥ä½œå‡½æ•°ï¼Œç”±å•ä¸ªè¿›ç¨‹æ‰§è¡Œï¼Œè´Ÿè´£å¤„ç†åˆ†é…ç»™å®ƒçš„ä¸€æ‰¹æ–‡ä»¶ã€‚
    """
    # --- 1. åœ¨å½“å‰è¿›ç¨‹ä¸­è®¾ç½®æ¨¡å‹ ---
    try:
        vae, feature_extractor, device = setup_audioldm2_vae(gpu_id)
    except Exception as e:
        print(f"[GPU-{gpu_id}]: æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return len(file_chunk), 0 # è¿”å›é”™è¯¯ï¼Œè¡¨ç¤ºæ‰€æœ‰æ–‡ä»¶éƒ½å¤±è´¥äº†

    error_count = 0
    success_count = 0

    # --- 2. éå†å¹¶å¤„ç†åˆ†é…ç»™è¿™ä¸ªè¿›ç¨‹çš„æ–‡ä»¶ ---
    # ä¸ºæ¯ä¸ªGPUåˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„è¿›åº¦æ¡
    progress_bar = tqdm(file_chunk, desc=f"GPU-{gpu_id} å¤„ç†ä¸­", position=gpu_id)
    
    for filename in progress_bar:
        video_path = os.path.join(input_dir, filename)
        base_name = os.path.splitext(filename)[0]
        output_path = os.path.join(output_dir, f"{base_name}.npy")

        # if os.path.exists(output_path):
        #     continue

        latent_np, status = encode_audio_from_video(video_path, vae, feature_extractor, device)

        if status == "SUCCESS" and latent_np is not None:
            np.save(output_path, latent_np)
            success_count += 1
        elif status != "NO_AUDIO":
            # å¦‚æœä¸æ˜¯å› ä¸ºæ²¡æœ‰éŸ³è½¨è€Œå¤±è´¥ï¼Œå°±æ‰“å°é”™è¯¯å¹¶è®¡æ•°
            tqdm.write(f"[GPU-{gpu_id} é”™è¯¯]: {status}")
            error_count += 1
            
    return error_count, success_count

def batch_process_videos_multi_gpu(input_dir, output_dir):
    """
    ä¸»å‡½æ•°ï¼šè´Ÿè´£ä»»åŠ¡åˆ†å‘å’Œå¯åŠ¨å¤šè¿›ç¨‹ã€‚
    """
    # --- 1. æ£€æŸ¥GPUæ•°é‡ ---
    if not torch.cuda.is_available():
        print("é”™è¯¯ï¼šæœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ã€‚è¯·åœ¨å•å¡CPU/GPUæ¨¡å¼ä¸‹è¿è¡Œã€‚")
        return

    num_gpus = torch.cuda.device_count()
    print(f"æ£€æµ‹åˆ° {num_gpus} å—å¯ç”¨çš„GPUã€‚")

    # --- 2. æ£€æŸ¥å¹¶åˆ›å»ºè¾“å‡ºç›®å½• ---
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"å·²åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")

    # --- 3. æŸ¥æ‰¾æ‰€æœ‰è¦å¤„ç†çš„ MP4 æ–‡ä»¶ ---
    all_files = sorted([f for f in os.listdir(input_dir) if f.lower().endswith(".mp4")])
    if not all_files:
        print(f"åœ¨ç›®å½• '{input_dir}' ä¸­æ²¡æœ‰æ‰¾åˆ° .mp4 æ–‡ä»¶ã€‚")
        return
        
    print(f"åœ¨è¾“å…¥ç›®å½•ä¸­æ‰¾åˆ° {len(all_files)} ä¸ª .mp4 æ–‡ä»¶ã€‚å‡†å¤‡åˆ†å‘ä»»åŠ¡...")

    # --- 4. å°†æ–‡ä»¶åˆ—è¡¨å¹³å‡åˆ†é…ç»™æ¯ä¸ªGPU ---
    # ä½¿ç”¨ np.array_split å¯ä»¥ä¼˜é›…åœ°å¤„ç†æ— æ³•æ•´é™¤çš„æƒ…å†µ
    file_chunks = np.array_split(all_files, num_gpus)
    
    # å‡†å¤‡ä¼ é€’ç»™æ¯ä¸ªå·¥ä½œè¿›ç¨‹çš„å‚æ•°
    tasks = []
    for gpu_id, chunk in enumerate(file_chunks):
        if len(chunk) > 0: # åªæœ‰å½“åˆ†é…åˆ°æ–‡ä»¶æ—¶æ‰åˆ›å»ºä»»åŠ¡
            tasks.append((gpu_id, list(chunk), input_dir, output_dir))
            print(f"  -> GPU-{gpu_id} å°†å¤„ç† {len(chunk)} ä¸ªæ–‡ä»¶ã€‚")

    # --- 5. åˆ›å»ºå¹¶å¯åŠ¨è¿›ç¨‹æ±  ---
    # ä½¿ç”¨ 'spawn' å¯åŠ¨æ–¹æ³•ï¼Œè¿™å¯¹CUDAæ˜¯å¿…é¡»çš„ï¼Œå¯ä»¥é¿å…å¾ˆå¤šæ½œåœ¨çš„æ­»é”é—®é¢˜
    ctx = mp.get_context('spawn')
    with ctx.Pool(processes=len(tasks)) as pool:
        # ä½¿ç”¨ starmap æ¥ä¼ é€’å¤šä¸ªå‚æ•°ç»™å·¥ä½œå‡½æ•°
        results = pool.starmap(process_files_on_gpu, tasks)

    # --- 6. æ±‡æ€»ç»“æœ ---
    total_errors = sum([res[0] for res in results])
    total_success = sum([res[1] for res in results])

    print("\n--- å¤„ç†å®Œæˆï¼Œç”ŸæˆæŠ¥å‘Š ---")
    print(f"æ€»è®¡æˆåŠŸå¤„ç†: {total_success} ä¸ªæ–‡ä»¶")
    print(f"æ€»è®¡å¤„ç†å¤±è´¥: {total_errors} ä¸ªæ–‡ä»¶")
    print("\nğŸ‰ æ‰€æœ‰è§†é¢‘å¤„ç†å®Œæˆï¼")


if __name__ == '__main__':
    # ä¸ºäº†åœ¨ä½¿ç”¨CUDAæ—¶è·å¾—æœ€ä½³çš„å¤šè¿›ç¨‹ç¨³å®šæ€§ï¼Œå»ºè®®è®¾ç½®å¯åŠ¨æ–¹æ³•
    # 'spawn' ä¼šåˆ›å»ºä¸€ä¸ªå…¨æ–°çš„Pythonè§£é‡Šå™¨è¿›ç¨‹ï¼Œè€Œä¸æ˜¯'fork'ä¸€ä¸ªç°æœ‰è¿›ç¨‹
    # è¿™å¯ä»¥é¿å…CUDAåˆå§‹åŒ–çŠ¶æ€åœ¨å­è¿›ç¨‹ä¸­å‡ºç°é—®é¢˜ã€‚
    # å¿…é¡»åœ¨ if __name__ == '__main__': å—çš„å¼€å¤´è®¾ç½®ã€‚
    try:
        mp.set_start_method('spawn', force=True)
    except RuntimeError:
        pass
        
    # video_directory_list=["vggsound_00_3s","vggsound_01_3s","vggsound_02_3s","vggsound_03_3s","vggsound_04_3s"]
    video_directory_list=["vggsound_05_3s","vggsound_06_3s","vggsound_07_3s","vggsound_08_3s","vggsound_09_3s","vggsound_10_3s","vggsound_11_3s","vggsound_12_3s","vggsound_13_3s","vggsound_14_3s"]
    input_video_directory_base="/blob/vggsound_cropped"
    output_latent_directory_base = "/blob/vggsound_cropped_audio_latent"
    # --------------------------
    for video_dir in video_directory_list:
        input_video_directory=os.path.join(input_video_directory_base,video_dir)
        output_latent_directory=os.path.join(output_latent_directory_base,video_dir)

        try:
            batch_process_videos_multi_gpu(input_video_directory, output_latent_directory)
        except Exception as e:
            print(f"\nç¨‹åºè¿è¡ŒæœŸé—´å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            print(traceback.format_exc())