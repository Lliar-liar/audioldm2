#!/usr/bin/env python
"""
ç‹¬ç«‹GPUè¿›ç¨‹ç‰ˆæœ¬ - ä½¿ç”¨DataLoaderä¼˜åŒ–I/Oæ€§èƒ½
"""

import os
import sys
import torch
import numpy as np
import torchaudio
import traceback
from pathlib import Path
from multiprocessing import Process
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
from typing import List, Dict, Tuple, Optional
import time
import json

# ============ è‡ªå®šä¹‰Dataset ============
class VideoAudioDataset(Dataset):
    """è§†é¢‘éŸ³é¢‘æ•°æ®é›†ï¼Œæ”¯æŒé«˜æ•ˆæ‰¹å¤„ç†"""
    
    def __init__(self, video_paths: List[str], output_paths: List[str], 
                 segment_length: int = 16000 * 3, skip_existing: bool = True):
        """
        Args:
            video_paths: è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_paths: å¯¹åº”çš„è¾“å‡ºè·¯å¾„åˆ—è¡¨
            segment_length: éŸ³é¢‘æ®µé•¿åº¦
            skip_existing: æ˜¯å¦è·³è¿‡å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶
        """
        self.segment_length = segment_length
        
        # è¿‡æ»¤å·²å­˜åœ¨çš„æ–‡ä»¶
        self.video_paths = []
        self.output_paths = []
        
        for video_path, output_path in zip(video_paths, output_paths):
            if skip_existing and os.path.exists(output_path):
                # éªŒè¯æ–‡ä»¶æœ‰æ•ˆæ€§
                try:
                    data = np.load(output_path)
                    if data.size > 0:
                        continue  # è·³è¿‡æœ‰æ•ˆçš„å·²å­˜åœ¨æ–‡ä»¶
                except:
                    pass  # æ–‡ä»¶æŸåï¼Œéœ€è¦é‡æ–°å¤„ç†
            
            self.video_paths.append(video_path)
            self.output_paths.append(output_path)
    
    def __len__(self):
        return len(self.video_paths)
    
    def __getitem__(self, idx):
        """åŠ è½½å•ä¸ªæ ·æœ¬"""
        video_path = self.video_paths[idx]
        output_path = self.output_paths[idx]
        
        try:
            # è¯»å–éŸ³é¢‘
            waveform, sr = torchaudio.load(video_path, format="mp4", backend="ffmpeg")
            
            # é‡é‡‡æ ·åˆ°16kHz
            if sr != 16000:
                waveform = torchaudio.functional.resample(waveform, orig_freq=sr, new_freq=16000)
            
            # è½¬æ¢ä¸ºå•å£°é“
            if waveform.shape[0] > 1:
                waveform = torch.mean(waveform, dim=0, keepdim=True)
            
            waveform = waveform.squeeze(0)
            
            # å½’ä¸€åŒ–
            waveform = waveform - torch.mean(waveform)
            max_val = torch.max(torch.abs(waveform))
            if max_val > 1e-8:
                waveform = waveform / max_val * 0.5
            
            # å¡«å……æˆ–è£å‰ª
            current_len = waveform.shape[0]
            if current_len > self.segment_length:
                waveform = waveform[:self.segment_length]
            elif current_len < self.segment_length:
                waveform = torch.nn.functional.pad(waveform, (0, self.segment_length - current_len))
            
            return {
                'waveform': waveform,
                'output_path': output_path,
                'status': 'success'
            }
        except Exception as e:
            # è¿”å›é”™è¯¯æ ‡è®°
            return {
                'waveform': torch.zeros(self.segment_length),
                'output_path': output_path,
                'status': f'error: {str(e)}'
            }

def collate_fn(batch):
    """è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°"""
    waveforms = []
    output_paths = []
    valid_indices = []
    
    for i, item in enumerate(batch):
        if item['status'] == 'success':
            waveforms.append(item['waveform'])
            output_paths.append(item['output_path'])
            valid_indices.append(i)
    
    if waveforms:
        waveforms = torch.stack(waveforms)
    else:
        waveforms = None
    
    return {
        'waveforms': waveforms,
        'output_paths': output_paths,
        'valid_indices': valid_indices
    }

# ============ éŸ³é¢‘å¤„ç†å‡½æ•° ============
def get_mel_from_wav_batch(audio_batch, _stft):
    """å¤„ç†ä¸€æ‰¹éŸ³é¢‘"""
    if audio_batch.dim() == 3:
        audio_batch = audio_batch.squeeze(1)
    elif audio_batch.dim() == 1:
        audio_batch = audio_batch.unsqueeze(0)
    
    assert audio_batch.dim() == 2, f"Expected 2D tensor, got {audio_batch.dim()}D"
    
    audio_batch = torch.clip(audio_batch, -1, 1)
    audio_batch = torch.autograd.Variable(audio_batch, requires_grad=False)
    
    melspec, magnitudes, phases, energy = _stft.mel_spectrogram(audio_batch)
    return melspec, magnitudes, energy

def _pad_spec(fbank, target_length=1024):
    """å¡«å……é¢‘è°±åˆ°ç›®æ ‡é•¿åº¦"""
    n_frames = fbank.shape[0]
    p = target_length - n_frames
    if p > 0:
        m = torch.nn.ZeroPad2d((0, 0, 0, p))
        fbank = m(fbank)
    elif p < 0:
        fbank = fbank[0:target_length, :]
    
    if fbank.size(-1) % 2 != 0:
        fbank = fbank[..., :-1]
    
    return fbank

# ============ å•GPUå¤„ç†è¿›ç¨‹ï¼ˆDataLoaderç‰ˆæœ¬ï¼‰============
def single_gpu_worker_dataloader(gpu_id: int, input_dirs: List[str], output_base: str, config: Dict):
    """ä½¿ç”¨DataLoaderçš„å•GPUå¤„ç†è¿›ç¨‹"""
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œåªä½¿ç”¨æŒ‡å®šçš„GPU
    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
    os.environ['CUDA_LAUNCH_BLOCKING'] = '0'
    
    device = torch.device("cuda:0")
    
    print(f"\n[GPU {gpu_id}] å¯åŠ¨DataLoaderä¼˜åŒ–è¿›ç¨‹")
    print(f"[GPU {gpu_id}] è´Ÿè´£å¤„ç† {len(input_dirs)} ä¸ªç›®å½•")
    
    try:
        # å¯¼å…¥å¿…è¦çš„åº“
        from diffusers import AutoencoderKL
        from audioldm2.utils import default_audioldm_config
        from audioldm2.utilities.audio.stft import TacotronSTFT
        
        # åŠ è½½VAEæ¨¡å‹
        print(f"[GPU {gpu_id}] åŠ è½½VAEæ¨¡å‹...")
        vae = AutoencoderKL.from_pretrained(
            "cvssp/audioldm2", 
            subfolder="vae", 
            torch_dtype=torch.float16,
            resume_download=True
        )
        vae = vae.to(device)
        vae.eval()
        for p in vae.parameters():
            p.requires_grad = False
        
        # è®¾ç½®STFT
        config_audio = default_audioldm_config()
        fn_STFT = TacotronSTFT(
            config_audio["preprocessing"]["stft"]["filter_length"],
            config_audio["preprocessing"]["stft"]["hop_length"],
            config_audio["preprocessing"]["stft"]["win_length"],
            config_audio["preprocessing"]["mel"]["n_mel_channels"],
            config_audio["preprocessing"]["audio"]["sampling_rate"],
            config_audio["preprocessing"]["mel"]["mel_fmin"],
            config_audio["preprocessing"]["mel"]["mel_fmax"],
        ).to(device)
        
        # è·å–GPUå†…å­˜å¹¶é€‰æ‹©é…ç½®
        memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        print(f"[GPU {gpu_id}] æ˜¾å­˜: {memory_gb:.1f}GB")
        
        # DataLoaderé…ç½®
        if memory_gb >= 70:  # 80GB
            batch_size = config.get('batch_size', 32)
            vae_chunk_size = config.get('vae_chunk_size', 32)
            num_workers = config.get('num_workers', 8)
            prefetch_factor = config.get('prefetch_factor', 4)
        elif memory_gb >= 35:  # 40GB
            batch_size = config.get('batch_size', 24)
            vae_chunk_size = config.get('vae_chunk_size', 24)
            num_workers = config.get('num_workers', 6)
            prefetch_factor = config.get('prefetch_factor', 3)
        else:  # 24GBæˆ–æ›´å°
            batch_size = config.get('batch_size', 16)
            vae_chunk_size = config.get('vae_chunk_size', 16)
            num_workers = config.get('num_workers', 4)
            prefetch_factor = config.get('prefetch_factor', 2)
        
        print(f"[GPU {gpu_id}] é…ç½®: batch_size={batch_size}, vae_chunk={vae_chunk_size}, workers={num_workers}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_processed = 0
        total_failed = 0
        total_skipped = 0
        start_time = time.time()
        
        # å¤„ç†æ¯ä¸ªåˆ†é…çš„ç›®å½•
        for dir_idx, input_dir in enumerate(input_dirs):
            dir_name = os.path.basename(input_dir)
            output_dir = os.path.join(output_base, dir_name)
            os.makedirs(output_dir, exist_ok=True)
            
            # è·å–æ‰€æœ‰è§†é¢‘æ–‡ä»¶
            video_files = sorted([f for f in os.listdir(input_dir) if f.endswith('.mp4')])
            if not video_files:
                print(f"[GPU {gpu_id}] ç›®å½• {dir_name} æ²¡æœ‰è§†é¢‘æ–‡ä»¶")
                continue
            
            # å‡†å¤‡è·¯å¾„
            video_paths = [os.path.join(input_dir, f) for f in video_files]
            output_paths = [os.path.join(output_dir, f.replace('.mp4', '.npy')) for f in video_files]
            
            # ç»Ÿè®¡å·²å­˜åœ¨çš„æ–‡ä»¶
            existing_count = sum(1 for p in output_paths if os.path.exists(p))
            total_skipped += existing_count
            
            # åˆ›å»ºæ•°æ®é›†
            dataset = VideoAudioDataset(
                video_paths, 
                output_paths, 
                segment_length=16000 * 3,
                skip_existing=True
            )
            
            if len(dataset) == 0:
                print(f"[GPU {gpu_id}] [{dir_idx+1}/{len(input_dirs)}] {dir_name}: æ‰€æœ‰ {len(video_files)} ä¸ªæ–‡ä»¶å·²å¤„ç†")
                continue
            
            print(f"[GPU {gpu_id}] [{dir_idx+1}/{len(input_dirs)}] {dir_name}: å¤„ç† {len(dataset)}/{len(video_files)} ä¸ªæ–‡ä»¶")
            
            # åˆ›å»ºDataLoader
            dataloader = DataLoader(
                dataset,
                batch_size=batch_size,
                shuffle=False,
                num_workers=num_workers,
                pin_memory=True,
                prefetch_factor=prefetch_factor,
                persistent_workers=True if num_workers > 0 else False,
                collate_fn=collate_fn,
                drop_last=False
            )
            
            # åˆ›å»ºè¿›åº¦æ¡
            pbar = tqdm(
                total=len(dataset),
                desc=f"GPU{gpu_id}-{dir_name}",
                position=gpu_id,
                leave=True
            )
            
            # å¤„ç†æ‰¹æ¬¡
            for batch_idx, batch in enumerate(dataloader):
                if batch['waveforms'] is None or len(batch['waveforms']) == 0:
                    continue
                
                try:
                    # ç§»åŠ¨åˆ°GPU
                    waveforms = batch['waveforms'].to(device, non_blocking=True)
                    output_paths_batch = batch['output_paths']
                    
                    # è®¡ç®—melé¢‘è°±
                    with torch.no_grad():
                        # å¤„ç†éŸ³é¢‘åˆ°mel
                        mel_batch, _, _ = get_mel_from_wav_batch(waveforms, fn_STFT)
                        
                        # å¤„ç†melé¢‘è°±ç»´åº¦
                        processed_mels = []
                        target_length = int(3 * 102.4)  # duration * 102.4
                        
                        for i in range(mel_batch.size(0)):
                            mel = mel_batch[i].T
                            mel = _pad_spec(mel, target_length)
                            processed_mels.append(mel)
                        
                        mel_batch = torch.stack(processed_mels)
                        mel_batch = mel_batch.unsqueeze(1).to(torch.float16)
                        
                        # VAEç¼–ç ï¼ˆåˆ†å—å¤„ç†ä»¥èŠ‚çœå†…å­˜ï¼‰
                        if mel_batch.size(0) > vae_chunk_size:
                            latent_list = []
                            for i in range(0, mel_batch.size(0), vae_chunk_size):
                                chunk = mel_batch[i:i+vae_chunk_size]
                                latent_chunk = vae.encode(chunk).latent_dist.mode()
                                latent_list.append(latent_chunk.cpu())
                            latents = torch.cat(latent_list, dim=0).numpy()
                        else:
                            latents = vae.encode(mel_batch).latent_dist.mode().cpu().numpy()
                    
                    # ä¿å­˜ç»“æœ
                    for latent, output_path in zip(latents, output_paths_batch):
                        try:
                            # åŸå­å†™å…¥é¿å…æŸå
                            temp_path = f"{output_path}.tmp_{gpu_id}"
                            np.save(temp_path, latent)
                            os.rename(temp_path, output_path)
                            total_processed += 1
                        except Exception as e:
                            print(f"[GPU {gpu_id}] ä¿å­˜å¤±è´¥ {os.path.basename(output_path)}: {e}")
                            total_failed += 1
                    
                except Exception as e:
                    print(f"[GPU {gpu_id}] æ‰¹å¤„ç†é”™è¯¯: {e}")
                    total_failed += len(batch['output_paths'])
                
                pbar.update(len(batch['output_paths']))
                
                # å®šæœŸæ¸…ç†ç¼“å­˜
                if batch_idx % 10 == 0:
                    torch.cuda.empty_cache()
            
            pbar.close()
        
        # ç»Ÿè®¡ä¿¡æ¯
        elapsed_time = time.time() - start_time
        print(f"\n[GPU {gpu_id}] å®Œæˆ!")
        print(f"  - æˆåŠŸå¤„ç†: {total_processed} ä¸ªæ–‡ä»¶")
        print(f"  - è·³è¿‡å·²å­˜åœ¨: {total_skipped} ä¸ªæ–‡ä»¶")
        print(f"  - å¤„ç†å¤±è´¥: {total_failed} ä¸ªæ–‡ä»¶")
        print(f"  - æ€»ç”¨æ—¶: {elapsed_time/60:.1f} åˆ†é’Ÿ")
        if total_processed > 0:
            print(f"  - å¤„ç†é€Ÿåº¦: {total_processed/elapsed_time:.2f} æ–‡ä»¶/ç§’")
        
    except Exception as e:
        print(f"[GPU {gpu_id}] å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
    finally:
        # æ¸…ç†
        if 'vae' in locals():
            del vae
        torch.cuda.empty_cache()

# ============ ä¸»æ§åˆ¶å™¨ ============
class DataLoaderGPUProcessor:
    """DataLoaderä¼˜åŒ–çš„GPUè¿›ç¨‹ç®¡ç†å™¨"""
    
    def __init__(self, num_gpus: int = None):
        """åˆå§‹åŒ–
        
        Args:
            num_gpus: è¦ä½¿ç”¨çš„GPUæ•°é‡ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU
        """
        available_gpus = torch.cuda.device_count()
        if num_gpus is None:
            self.num_gpus = available_gpus
        else:
            self.num_gpus = min(num_gpus, available_gpus)
        
        print(f"DataLoader GPUå¤„ç†å™¨åˆå§‹åŒ–")
        print(f"  - å¯ç”¨GPU: {available_gpus}")
        print(f"  - ä½¿ç”¨GPU: {self.num_gpus}")
    
    def distribute_directories(self, directories: List[str]) -> Dict[int, List[str]]:
        """å°†ç›®å½•åˆ†é…ç»™å„ä¸ªGPU"""
        assignments = {i: [] for i in range(self.num_gpus)}
        
        for idx, directory in enumerate(directories):
            gpu_id = idx % self.num_gpus
            assignments[gpu_id].append(directory)
        
        return assignments
    
    def process(self, input_base: str, output_base: str, dir_list: List[str], config: Dict = None):
        """å¯åŠ¨DataLoaderä¼˜åŒ–çš„GPUè¿›ç¨‹å¤„ç†"""
        if config is None:
            config = {}
        
        # å‡†å¤‡å®Œæ•´è·¯å¾„
        full_paths = [os.path.join(input_base, d) for d in dir_list]
        
        # åˆ†é…å·¥ä½œ
        gpu_assignments = self.distribute_directories(full_paths)
        
        # æ˜¾ç¤ºåˆ†é…æƒ…å†µ
        print("\nå·¥ä½œåˆ†é…:")
        for gpu_id, dirs in gpu_assignments.items():
            if dirs:
                print(f"  GPU {gpu_id}: {len(dirs)} ä¸ªç›®å½• - {[os.path.basename(d) for d in dirs]}")
        
        # å¯åŠ¨è¿›ç¨‹
        processes = []
        print("\nå¯åŠ¨GPUè¿›ç¨‹ï¼ˆDataLoaderä¼˜åŒ–ï¼‰...")
        
        for gpu_id, assigned_dirs in gpu_assignments.items():
            if not assigned_dirs:
                continue
            
            # åˆ›å»ºè¿›ç¨‹
            p = Process(
                target=single_gpu_worker_dataloader,
                args=(gpu_id, assigned_dirs, output_base, config)
            )
            p.start()
            processes.append((gpu_id, p))
            
            # ç¨å¾®é”™å¼€å¯åŠ¨
            time.sleep(2)
        
        print(f"å·²å¯åŠ¨ {len(processes)} ä¸ªGPUè¿›ç¨‹\n")
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        for gpu_id, p in processes:
            p.join()
            print(f"GPU {gpu_id} è¿›ç¨‹å·²å®Œæˆ")
        
        print("\nâœ… æ‰€æœ‰GPUè¿›ç¨‹å·²å®Œæˆ!")

# ============ è¿›åº¦æ£€æŸ¥å‡½æ•° ============
def check_progress(input_base: str, output_base: str, dir_list: List[str]):
    """æ£€æŸ¥å¤„ç†è¿›åº¦"""
    print("\nğŸ“Š å¤„ç†è¿›åº¦ç»Ÿè®¡:")
    print("-" * 60)
    
    total_videos = 0
    total_processed = 0
    total_corrupted = 0
    
    for dir_name in dir_list:
        input_dir = os.path.join(input_base, dir_name)
        output_dir = os.path.join(output_base, dir_name)
        
        if not os.path.exists(input_dir):
            print(f"âŒ {dir_name}: è¾“å…¥ç›®å½•ä¸å­˜åœ¨")
            continue
        
        # ç»Ÿè®¡è§†é¢‘æ–‡ä»¶
        video_files = [f for f in os.listdir(input_dir) if f.endswith('.mp4')]
        num_videos = len(video_files)
        total_videos += num_videos
        
        # ç»Ÿè®¡å·²å¤„ç†çš„æ–‡ä»¶
        if os.path.exists(output_dir):
            processed = 0
            corrupted = 0
            
            for video_file in video_files:
                output_file = os.path.join(output_dir, video_file.replace('.mp4', '.npy'))
                if os.path.exists(output_file):
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
                    try:
                        data = np.load(output_file)
                        if data.size > 0:
                            processed += 1
                        else:
                            corrupted += 1
                    except:
                        corrupted += 1
            
            total_processed += processed
            total_corrupted += corrupted
            
            percentage = (processed / num_videos * 100) if num_videos > 0 else 0
            status = "âœ…" if processed == num_videos else "ğŸ”„"
            
            print(f"{status} {dir_name}: {processed}/{num_videos} ({percentage:.1f}%)")
            if corrupted > 0:
                print(f"   âš ï¸ æŸåæ–‡ä»¶: {corrupted}")
        else:
            print(f"â³ {dir_name}: 0/{num_videos} (0.0%) - è¾“å‡ºç›®å½•ä¸å­˜åœ¨")
    
    print("-" * 60)
    overall_percentage = (total_processed / total_videos * 100) if total_videos > 0 else 0
    print(f"ğŸ“ˆ æ€»ä½“è¿›åº¦: {total_processed}/{total_videos} ({overall_percentage:.1f}%)")
    if total_corrupted > 0:
        print(f"âš ï¸ æ€»æŸåæ–‡ä»¶: {total_corrupted}")
    
    return total_processed, total_videos

# ============ ä¾¿æ·å‡½æ•° ============
def auto_process_videos_dataloader(input_base: str, output_base: str, dir_list: List[str], 
                                  num_gpus: int = None, batch_size: int = None, 
                                  num_workers: int = None):
    """ä½¿ç”¨DataLoaderä¼˜åŒ–çš„è‡ªåŠ¨å¤„ç†å‡½æ•°
    
    Args:
        input_base: è¾“å…¥åŸºç¡€ç›®å½•
        output_base: è¾“å‡ºåŸºç¡€ç›®å½•  
        dir_list: è¦å¤„ç†çš„å­ç›®å½•åˆ—è¡¨
        num_gpus: ä½¿ç”¨çš„GPUæ•°é‡ï¼ˆNone=å…¨éƒ¨ï¼‰
        batch_size: æ‰¹å¤„ç†å¤§å°ï¼ˆNone=è‡ªåŠ¨ï¼‰
        num_workers: DataLoaderå·¥ä½œçº¿ç¨‹æ•°ï¼ˆNone=è‡ªåŠ¨ï¼‰
    """
    config = {}
    if batch_size is not None:
        config['batch_size'] = batch_size
    if num_workers is not None:
        config['num_workers'] = num_workers
    
    processor = DataLoaderGPUProcessor(num_gpus)
    processor.process(input_base, output_base, dir_list, config)

# ============ ä¸»ç¨‹åº ============
if __name__ == '__main__':
    import multiprocessing as mp
    import argparse
    
    # å‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='æ‰¹é‡å¤„ç†è§†é¢‘éŸ³é¢‘ç¼–ç ï¼ˆDataLoaderä¼˜åŒ–ç‰ˆï¼‰')
    parser.add_argument('--check', action='store_true', help='åªæ£€æŸ¥è¿›åº¦ï¼Œä¸å¤„ç†')
    parser.add_argument('--gpus', type=int, help='ä½¿ç”¨çš„GPUæ•°é‡')
    parser.add_argument('--batch-size', type=int, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--workers', type=int, help='DataLoaderå·¥ä½œçº¿ç¨‹æ•°')
    
    args = parser.parse_args()
    
    # è®¾ç½®å¯åŠ¨æ–¹æ³•
    try:
        mp.set_start_method('spawn', force=True)
    except RuntimeError:
        pass
    
    # é…ç½®
    video_directory_list = [
        "vggsound_00_3s", 
        "vggsound_01_3s", 
        "vggsound_02_3s", 
        "vggsound_03_3s", 
        "vggsound_04_3s",
        "vggsound_05_3s", 
        "vggsound_06_3s", 
        "vggsound_07_3s", 
        "vggsound_08_3s", 
        "vggsound_09_3s",
    ]
    
    input_video_directory_base = "/blob/vggsound_cropped"
    output_latent_directory_base = "/blob/vggsound_cropped_audio_latent_fixed"
    
    # æ£€æŸ¥è¿›åº¦
    if args.check:
        check_progress(
            input_video_directory_base,
            output_latent_directory_base,
            video_directory_list
        )
    else:
        # è¿è¡Œå¤„ç†
        auto_process_videos_dataloader(
            input_video_directory_base,
            output_latent_directory_base,
            video_directory_list,
            num_gpus=args.gpus,
            batch_size=args.batch_size,
            num_workers=args.workers
        )
