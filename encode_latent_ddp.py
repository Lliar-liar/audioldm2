import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
import torchaudio
from pathlib import Path
import time
from typing import List, Tuple, Optional
import os
from tqdm import tqdm
import traceback

# ============ è‡ªå®šä¹‰Dataset ============
class VideoAudioDataset(Dataset):
    """è§†é¢‘éŸ³é¢‘æ•°æ®é›†ï¼Œæ”¯æŒé«˜æ•ˆæ‰¹å¤„ç†"""
    
    def __init__(self, video_paths: List[str], output_paths: List[str], 
                 segment_length: int = 16000 * 3, skip_existing: bool = True):
        """
        Args:
            video_paths: è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_paths: å¯¹åº”çš„è¾“å‡ºè·¯å¾„åˆ—è¡¨
            segment_length: éŸ³é¢‘æ®µé•¿åº¦
            skip_existing: æ˜¯å¦è·³è¿‡å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶
        """
        self.segment_length = segment_length
        
        # è¿‡æ»¤å·²å­˜åœ¨çš„æ–‡ä»¶
        self.video_paths = []
        self.output_paths = []
        
        for video_path, output_path in zip(video_paths, output_paths):
            if skip_existing and os.path.exists(output_path):
                # éªŒè¯æ–‡ä»¶æœ‰æ•ˆæ€§
                try:
                    data = np.load(output_path)
                    if data.size > 0:
                        continue  # è·³è¿‡æœ‰æ•ˆçš„å·²å­˜åœ¨æ–‡ä»¶
                except:
                    pass  # æ–‡ä»¶æŸåï¼Œéœ€è¦é‡æ–°å¤„ç†
            
            self.video_paths.append(video_path)
            self.output_paths.append(output_path)
        
        print(f"æ•°æ®é›†: {len(self.video_paths)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")
    
    def __len__(self):
        return len(self.video_paths)
    
    def __getitem__(self, idx):
        """åŠ è½½å•ä¸ªæ ·æœ¬"""
        video_path = self.video_paths[idx]
        output_path = self.output_paths[idx]
        
        try:
            # è¯»å–éŸ³é¢‘
            waveform, sr = torchaudio.load(video_path, format="mp4", backend="ffmpeg")
            
            # é‡é‡‡æ ·åˆ°16kHz
            if sr != 16000:
                waveform = torchaudio.functional.resample(waveform, orig_freq=sr, new_freq=16000)
            
            # è½¬æ¢ä¸ºå•å£°é“
            if waveform.shape[0] > 1:
                waveform = torch.mean(waveform, dim=0, keepdim=True)
            
            # å½’ä¸€åŒ–å’Œå¡«å……
            waveform = waveform.squeeze(0)
            waveform = self.normalize_wav(waveform)
            waveform = self.pad_wav(waveform)
            
            return {
                'waveform': waveform,
                'output_path': output_path,
                'status': 'success'
            }
        except Exception as e:
            # è¿”å›é”™è¯¯æ ‡è®°
            return {
                'waveform': torch.zeros(self.segment_length),
                'output_path': output_path,
                'status': f'error: {str(e)}'
            }
    
    def normalize_wav(self, waveform):
        """å½’ä¸€åŒ–æ³¢å½¢"""
        waveform = waveform - torch.mean(waveform)
        max_val = torch.max(torch.abs(waveform))
        if max_val > 1e-8:
            waveform = waveform / max_val * 0.5
        return waveform
    
    def pad_wav(self, waveform):
        """å¡«å……æˆ–è£å‰ªæ³¢å½¢"""
        current_len = waveform.shape[0]
        if current_len == self.segment_length:
            return waveform
        elif current_len > self.segment_length:
            return waveform[:self.segment_length]
        else:
            return torch.nn.functional.pad(waveform, (0, self.segment_length - current_len))

def collate_fn(batch):
    """è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°"""
    waveforms = []
    output_paths = []
    valid_indices = []
    
    for i, item in enumerate(batch):
        if item['status'] == 'success':
            waveforms.append(item['waveform'])
            output_paths.append(item['output_path'])
            valid_indices.append(i)
    
    if waveforms:
        waveforms = torch.stack(waveforms)
    else:
        waveforms = None
    
    return {
        'waveforms': waveforms,
        'output_paths': output_paths,
        'valid_indices': valid_indices
    }

# ============ ä¼˜åŒ–çš„å¤„ç†å‡½æ•° ============
def process_with_dataloader(gpu_id: int, input_dirs: List[str], output_base: str, config: Dict):
    """ä½¿ç”¨DataLoaderçš„ä¼˜åŒ–å¤„ç†å‡½æ•°"""
    
    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
    device = torch.device("cuda:0")
    
    print(f"\n[GPU {gpu_id}] å¯åŠ¨DataLoaderç‰ˆæœ¬")
    
    try:
        # å¯¼å…¥æ¨¡å‹
        from diffusers import AutoencoderKL
        from audioldm2.utils import default_audioldm_config
        from audioldm2.utilities.audio.stft import TacotronSTFT
        
        # åŠ è½½æ¨¡å‹
        vae = AutoencoderKL.from_pretrained(
            "cvssp/audioldm2", 
            subfolder="vae", 
            torch_dtype=torch.float16
        ).to(device).eval()
        
        # STFT
        config_audio = default_audioldm_config()
        fn_STFT = TacotronSTFT(
            config_audio["preprocessing"]["stft"]["filter_length"],
            config_audio["preprocessing"]["stft"]["hop_length"],
            config_audio["preprocessing"]["stft"]["win_length"],
            config_audio["preprocessing"]["mel"]["n_mel_channels"],
            config_audio["preprocessing"]["audio"]["sampling_rate"],
            config_audio["preprocessing"]["mel"]["mel_fmin"],
            config_audio["preprocessing"]["mel"]["mel_fmax"],
        ).to(device)
        
        # è·å–é…ç½®
        memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        
        # DataLoaderé…ç½®
        if memory_gb >= 70:  # 80GB GPU
            batch_size = config.get('batch_size', 32)
            num_workers = config.get('num_workers', 8)
            prefetch_factor = config.get('prefetch_factor', 4)
        elif memory_gb >= 35:  # 40GB GPU
            batch_size = config.get('batch_size', 24)
            num_workers = config.get('num_workers', 6)
            prefetch_factor = config.get('prefetch_factor', 3)
        else:  # 24GB GPU
            batch_size = config.get('batch_size', 16)
            num_workers = config.get('num_workers', 4)
            prefetch_factor = config.get('prefetch_factor', 2)
        
        print(f"[GPU {gpu_id}] é…ç½®: batch_size={batch_size}, workers={num_workers}")
        
        total_processed = 0
        total_failed = 0
        
        # å¤„ç†æ¯ä¸ªç›®å½•
        for dir_idx, input_dir in enumerate(input_dirs):
            dir_name = os.path.basename(input_dir)
            output_dir = os.path.join(output_base, dir_name)
            os.makedirs(output_dir, exist_ok=True)
            
            # å‡†å¤‡æ–‡ä»¶åˆ—è¡¨
            video_files = sorted([f for f in os.listdir(input_dir) if f.endswith('.mp4')])
            video_paths = [os.path.join(input_dir, f) for f in video_files]
            output_paths = [os.path.join(output_dir, f.replace('.mp4', '.npy')) for f in video_files]
            
            # åˆ›å»ºæ•°æ®é›†
            dataset = VideoAudioDataset(video_paths, output_paths, skip_existing=True)
            
            if len(dataset) == 0:
                print(f"[GPU {gpu_id}] {dir_name}: æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†")
                continue
            
            # åˆ›å»ºDataLoader
            dataloader = DataLoader(
                dataset,
                batch_size=batch_size,
                shuffle=False,
                num_workers=num_workers,
                pin_memory=True,
                prefetch_factor=prefetch_factor,
                persistent_workers=True if num_workers > 0 else False,
                collate_fn=collate_fn
            )
            
            # å¤„ç†æ‰¹æ¬¡
            pbar = tqdm(
                total=len(dataset),
                desc=f"GPU{gpu_id}-{dir_name}",
                position=gpu_id
            )
            
            for batch_idx, batch in enumerate(dataloader):
                if batch['waveforms'] is None:
                    continue
                
                # ç§»åŠ¨åˆ°GPU
                waveforms = batch['waveforms'].to(device, non_blocking=True)
                output_paths_batch = batch['output_paths']
                
                # è®¡ç®—melé¢‘è°±
                with torch.no_grad():
                    # å¤„ç†éŸ³é¢‘åˆ°mel
                    mel_batch, _, _ = get_mel_from_wav_batch(waveforms, fn_STFT)
                    mel_batch = mel_batch.unsqueeze(1).to(torch.float16)
                    
                    # VAEç¼–ç 
                    latents = vae.encode(mel_batch).latent_dist.mode()
                    latents = latents.cpu().numpy()
                
                # ä¿å­˜ç»“æœ
                for latent, output_path in zip(latents, output_paths_batch):
                    try:
                        # åŸå­å†™å…¥
                        temp_path = f"{output_path}.tmp_{gpu_id}"
                        np.save(temp_path, latent)
                        os.rename(temp_path, output_path)
                        total_processed += 1
                    except Exception as e:
                        print(f"[GPU {gpu_id}] ä¿å­˜å¤±è´¥: {e}")
                        total_failed += 1
                
                pbar.update(len(output_paths_batch))
                
                # å®šæœŸæ¸…ç†ç¼“å­˜
                if batch_idx % 10 == 0:
                    torch.cuda.empty_cache()
            
            pbar.close()
        
        print(f"[GPU {gpu_id}] å®Œæˆ: æˆåŠŸ={total_processed}, å¤±è´¥={total_failed}")
        
    except Exception as e:
        print(f"[GPU {gpu_id}] é”™è¯¯: {e}")
        traceback.print_exc()

# ============ æ€§èƒ½åŸºå‡†æµ‹è¯• ============
class PerformanceBenchmark:
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    
    @staticmethod
    def benchmark_no_dataloader(video_paths: List[str], batch_size: int = 16):
        """æµ‹è¯•æ— DataLoaderç‰ˆæœ¬"""
        start_time = time.time()
        processed = 0
        
        for i in range(0, len(video_paths), batch_size):
            batch = video_paths[i:i+batch_size]
            # ä¸²è¡Œè¯»å–
            for path in batch:
                try:
                    waveform, sr = torchaudio.load(path, format="mp4", backend="ffmpeg")
                    processed += 1
                except:
                    pass
        
        elapsed = time.time() - start_time
        return processed, elapsed, processed / elapsed
    
    @staticmethod
    def benchmark_with_dataloader(video_paths: List[str], batch_size: int = 16, num_workers: int = 4):
        """æµ‹è¯•DataLoaderç‰ˆæœ¬"""
        dataset = VideoAudioDataset(video_paths, [f"{p}.npy" for p in video_paths])
        dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            num_workers=num_workers,
            pin_memory=True,
            prefetch_factor=2
        )
        
        start_time = time.time()
        processed = 0
        
        for batch in dataloader:
            processed += len(batch['valid_indices'])
        
        elapsed = time.time() - start_time
        return processed, elapsed, processed / elapsed

# ============ æ€§èƒ½å¯¹æ¯”è„šæœ¬ ============
def compare_performance(input_dir: str, num_files: int = 100):
    """å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„æ€§èƒ½"""
    print("\nğŸ“Š æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    # è·å–æµ‹è¯•æ–‡ä»¶
    video_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.mp4')][:num_files]
    
    if not video_files:
        print("æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        return
    
    print(f"æµ‹è¯•æ–‡ä»¶æ•°: {len(video_files)}")
    
    # æµ‹è¯•ä¸åŒé…ç½®
    configs = [
        {"batch_size": 8, "num_workers": 0, "name": "å•çº¿ç¨‹"},
        {"batch_size": 8, "num_workers": 2, "name": "2çº¿ç¨‹"},
        {"batch_size": 8, "num_workers": 4, "name": "4çº¿ç¨‹"},
        {"batch_size": 16, "num_workers": 4, "name": "å¤§æ‰¹æ¬¡+4çº¿ç¨‹"},
    ]
    
    print("\næ— DataLoaderç‰ˆæœ¬:")
    benchmark = PerformanceBenchmark()
    processed, elapsed, throughput = benchmark.benchmark_no_dataloader(video_files, batch_size=16)
    baseline_throughput = throughput
    print(f"  å¤„ç†: {processed} æ–‡ä»¶")
    print(f"  è€—æ—¶: {elapsed:.2f} ç§’")
    print(f"  åå: {throughput:.2f} æ–‡ä»¶/ç§’")
    
    print("\nDataLoaderç‰ˆæœ¬:")
    for config in configs:
        processed, elapsed, throughput = benchmark.benchmark_with_dataloader(
            video_files, 
            batch_size=config["batch_size"],
            num_workers=config["num_workers"]
        )
        speedup = throughput / baseline_throughput
        print(f"\n  {config['name']}:")
        print(f"    å¤„ç†: {processed} æ–‡ä»¶")
        print(f"    è€—æ—¶: {elapsed:.2f} ç§’")
        print(f"    åå: {throughput:.2f} æ–‡ä»¶/ç§’")
        print(f"    åŠ é€Ÿ: {speedup:.2f}x")

# ============ ä¸»ç¨‹åº ============
if __name__ == '__main__':
    import argparse
    import multiprocessing as mp
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--benchmark', action='store_true', help='è¿è¡Œæ€§èƒ½æµ‹è¯•')
    parser.add_argument('--use-dataloader', action='store_true', help='ä½¿ç”¨DataLoaderç‰ˆæœ¬')
    parser.add_argument('--workers', type=int, default=4, help='DataLoaderå·¥ä½œçº¿ç¨‹æ•°')
    
    args = parser.parse_args()
    
    if args.benchmark:
        # è¿è¡Œæ€§èƒ½å¯¹æ¯”
        compare_performance("/blob/vggsound_cropped/vggsound_15_3s", num_files=100)
    else:
        # æ­£å¸¸å¤„ç†
        video_directory_list = [
            "vggsound_15_3s", 
            "vggsound_16_3s", 
            "vggsound_17_3s", 
            "vggsound_18_3s", 
            "vggsound_19_3s"
        ]
        
        config = {
            'num_workers': args.workers,
            'prefetch_factor': 2
        }
        
        if args.use_dataloader:
            print("ä½¿ç”¨DataLoaderä¼˜åŒ–ç‰ˆæœ¬")
            # ä½¿ç”¨DataLoaderç‰ˆæœ¬
            mp.set_start_method('spawn', force=True)
            # ... å¯åŠ¨process_with_dataloader
        else:
            print("ä½¿ç”¨åŸå§‹ç‰ˆæœ¬")
            # ä½¿ç”¨åŸå§‹ç‰ˆæœ¬
